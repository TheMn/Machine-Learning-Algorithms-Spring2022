{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "725da7dc-3663-4257-b53d-c5f613b5ba9c",
   "metadata": {},
   "source": [
    "# ![LOGO](utlogo.png)\n",
    "\n",
    "### تمرین سوم درس الگوریتم‌های یادگیری ماشین - امیرحسین مهدی‌نژاد - شماره دانشجویی ۸۱۰۸۰۰۰۵۸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfe96aa4-8fd2-4e14-9141-7b9f63706553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.jp-RenderedMarkdown{direction:rtl;display:flex;flex-direction:column;font-family:'IRANSans,Tahoma,Helvetica,sans-serif';margin-top:10px;font-size:1.1rem;direction:rtl}mark{color:#FFF;padding:3px; background-color:#AAAAAAA0}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.jp-RenderedMarkdown{direction:rtl;display:flex;flex-direction:column;font-family:'IRANSans,Tahoma,Helvetica,sans-serif';margin-top:10px;font-size:1.1rem;direction:rtl}mark{color:#FFF;padding:3px; background-color:#AAAAAAA0}</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa4bc73-1d74-44a2-803a-06e18d4d9f18",
   "metadata": {},
   "source": [
    "### سوال اول\n",
    "#### اضافه کردن کتابخانه‌های مورد استفاده"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64681292-e7b0-413a-8053-b35d14229910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /home/themn/Documents/Projects/Machine-Learning-Algorithms-Spring2022/env/lib/python3.8/site-packages (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/themn/Documents/Projects/Machine-Learning-Algorithms-Spring2022/env/lib/python3.8/site-packages (from h5py) (1.22.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fddced84-619e-4297-8315-9514669d71a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc2df0-b083-4154-b6f8-dc7a0ae2aae4",
   "metadata": {},
   "source": [
    "#### تابع لود کردن داده‌ها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddff8fcb-1254-4d75-9828-c8e8024ef8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(train_path, test_path):\n",
    "    train_dataset = h5py.File(train_path, \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File(test_path, \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057cfca6-6955-4579-bf2c-d482305f8f95",
   "metadata": {},
   "source": [
    "#### پیاده‌سازی تابع زیگموید\n",
    "##### یک مقدار را به عنوان پارامتر ورودی گرفته و sigmoid آن را محاسبه می‌کند\n",
    "$$\\sigma(z) = \\frac{1}{1+e^{-z}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633abba7-7b1e-4934-b8ff-34aaf2f42af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    '''\n",
    "        input: z (a scalar)\n",
    "        output: sigmoid(z)\n",
    "    '''\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe1b1c-9b72-4443-92db-ccd5f5a6f1ba",
   "metadata": {},
   "source": [
    "#### مقدار دهی weights و bias\n",
    "##### وکتور w و b با صفر مقداردهی اولیه می‌شوند"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af12f60-5450-4b6d-86d4-7e560038de33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    '''\n",
    "        input: dim (size of the w vector)\n",
    "        output: - w: initilized vector of size (dim, 1)\n",
    "                - b: initialized scalar\n",
    "    '''\n",
    "    return np.zeros((dim, 1)), 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4950d173-5fc5-4a9c-a0f0-c630c2c13547",
   "metadata": {},
   "source": [
    "#### پیاده‌سازی forward propagation و backward propagation برای یادگیری پارامترها\n",
    "#####  بدین منظور از forward propagation برای محاسبه‌ی تابع هزینه و خروجی y استفاده شده و همچنین برای محاسبه‌ی گرادیان نزولی backward propagation را داریم."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d24670-654a-4993-894b-a48adae8e128",
   "metadata": {},
   "source": [
    "$$ a^{(i)} = \\sigma(w^Tx^{(i)} + b) $$\n",
    "$$ J = \\frac{1}{m}\\sum_{i=1}^{m}-y^{(i)}\\log(a^{(i)})-(1-y^{(i)})\\log(1-a^{(i)}) $$\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T $$\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m}\\sum_{i=1}^{m}(a^{(i)}-y^{(i)}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b44da88-3f9d-47ea-ace1-fd5ff406d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, x, y):\n",
    "    '''\n",
    "        input: - w: weights, a numpy array of size (px * px * 3, 1)\n",
    "               - b: bias\n",
    "               - x: data of size (px * px * 3, number of examples)\n",
    "               - y: label vector of size (1, number of examples)  \n",
    "\n",
    "        output:\n",
    "               - cost: cost for logistic regression\n",
    "               - dw: gradient of the loss with respect to w\n",
    "               - db: gradient of the loss with respect to b\n",
    "    '''\n",
    "    m = x.shape[1]\n",
    "    \n",
    "    # Forward Propagation:\n",
    "    activation = sigmoid(np.dot(w.T, x) + b)\n",
    "    cost = -(1/m)*(np.sum(y*np.log(activation) + (1-y)*np.log(1-activation)))\n",
    "\n",
    "    # Backward Propagation\n",
    "    gradient = {'dw': (1/m)*np.dot(x, (activation-y).T), \n",
    "                'db': (1/m)*np.sum(activation-y)}\n",
    "\n",
    "    return gradient, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f6ea76-0883-4d20-9690-8532a9474fb6",
   "metadata": {},
   "source": [
    "#### کمینه کردن مقدار تابع هزینه\n",
    "##### در واقع با بکارگیری الگوریتم گرادیان کاهشی پارامترهای b و w بهینه می‌شوند. هزینه در هر ۱۰۰ اجرا یک بار چاپ می‌شود"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73e69e-a0cc-435b-9f1b-96c8994cff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, x, y, num_iterations, lr):\n",
    "    '''\n",
    "        input: - w: weights, a numpy array of size (px * px * 3, 1)\n",
    "               - b: bias\n",
    "               - x: data of size (px * px * 3, number of examples)\n",
    "               - y: label vector of size (1, number of examples) \n",
    "               - num_iterations: number of iterations of the optimization loop\n",
    "               - lr: learning_rate, for the GD update rule\n",
    "        \n",
    "        output:\n",
    "               - params: dictionary containing w and b\n",
    "               - grads: dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "               - costs: list of all the costs computed during the optimization, this will be used to plot the learning curve\n",
    "    '''\n",
    "    costs = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        gradient, cost = propagate(w, b, x, y)\n",
    "\n",
    "        dw, db = gradient['dw'], gradient['db']\n",
    "        \n",
    "        w -= lr*dw\n",
    "        b -= lr*db\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            print('{}th iteration cost: {:. 2f}'.format(i, cost))\n",
    "\n",
    "    return {'w': w, 'b': b},\\\n",
    "            {'dw': dw, 'db': db}\\\n",
    "            costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f0819e-e167-40c7-a7b4-96ca69268316",
   "metadata": {},
   "source": [
    "#### بروزرسانی مقادیر با گرادیان کاهشی\n",
    "##### پس از تعیین خروجی و تابع هزینه، باید مقادیر بهینه را پیدا کنیم تا ارور را به حداقل برسانیم و هزینه را کاهش دهیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d7edd-abc2-4844-9601-8da4ad0281ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, x):\n",
    "    '''\n",
    "        input: - w: weights (px * px * 3, 1)\n",
    "               - b: bias\n",
    "               - x: data of size (px * px * 3, number of examples)\n",
    "        \n",
    "        output:\n",
    "               - y_pred: np array containing all predictions (0 / 1) for examples in x\n",
    "    '''\n",
    "    m = x.shape[1]\n",
    "    y_pred = np.zeros((1, m))\n",
    "    w = w.reshape(x.shape[0], 1)\n",
    "    activation = sigmoid(np.dot(w.T, x) + b)\n",
    "\n",
    "    for i in range(activation.shape[1]):\n",
    "        y_pred[0,i] = 1 if activation[0, i] > 0.5 else 0\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dacbe9-23bd-4ddf-994f-5826c22496f7",
   "metadata": {},
   "source": [
    "##### هدف رگرسیون لجستیکی کاهش وزن‌ها و بهبود صحت خروجی است که با استفاده از تابع گرادیان کاهشی بدست می‌آید.\n",
    "##### طبق خواسته‌ی تمرین، در تابع model از توابع تعریف شده برای پیاده‌سازی رگرسیون لجستیکی استفاده می‌کنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886c919-8758-4d59-9ca5-09c5f4742c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, y_train, X_test, y_test, num_iterations = 2000, lr = 0.5):\n",
    "   \n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    parameters, gradients, costs = optimize(w, b, X_train, y_train, num_iterations, lr)\n",
    "    \n",
    "    w, b = parameters['w'], parameters['b']\n",
    "\n",
    "    y_pred_train = predict(w, b, X_train)\n",
    "    y_pred_test = predict(w, b, X_test)\n",
    "    \n",
    "    print('train acc: {:. 2f}'.format(100 - np.mean(np.abs(y_pred_train - y_train)) * 100),\\\n",
    "        'test acc: {:. 2f}'.format(100 - np.mean(np.abs(y_pred_test - y_test)) * 100) )\n",
    "\n",
    "    return {'y_pred_train': y_pred_train,\n",
    "            'y_pred_test': y_pred_test,\n",
    "            'w': w,\n",
    "            'b': b,\n",
    "            'costs': costs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fd75e9-873b-47f3-8547-18f3e5aeb4f2",
   "metadata": {},
   "source": [
    "##### اجرای قطعه کد برای داده‌های تمرین"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f069c84c-e56a-4e0c-b61f-49bfbda871a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
